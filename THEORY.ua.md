# Теоретичні питання

У цьому файлі наведені відповіді на теоретичну частину тестового завдання.
Відповіді зосереджені на архітектурних рішеннях, консистентності даних та production-підходах.

---

## 1. Zero-downtime міграція legacy PostgreSQL бази даних

### Етап 0. Підготовка та планування безпечної міграції

Перед виконанням будь-яких змін у production-середовищі необхідно пройти pre-migration checklist.
Цей етап мінімізує ризики та є обов’язковим для zero-downtime міграцій.

**Резервне копіювання даних (disaster recovery)**  
Перед міграцією створюється повний backup бази даних. Backup — це *останній рубіж* у випадку критичного збою, але **не основний rollback-механізм** у zero-downtime сценаріях.

Для PostgreSQL може використовуватись `pg_dump` для створення консистентного snapshot’у.

**Тестування в staging-середовищі**  
Staging має бути максимально схожим на production (версія PostgreSQL, схема БД, конфігурація, код) та містити snapshot production-даних або репрезентативний обсяг.

У staging:
- проганяються всі міграції та backfill;
- перевіряється відсутність довгих блокувань (`ALTER TABLE`, індекси);
- оцінюється вплив на продуктивність і стабільність застосунку;
- для міграцій може бути налаштований `lock_timeout`, щоб уникати довгих блокувань і краще аварійно зупинити деплой, ніж спричинити downtime.

Для цього можуть використовуватись:
- PostgreSQL views (`pg_stat_activity`, `pg_locks`, `pg_stat_statements`);
- GUI-інструменти (pgAdmin, DataGrip, DBeaver);
- метрики БД (наприклад, PostgreSQL exporter + Prometheus).

**Моніторинг продуктивності**  
Під час міграції та після read switch контролюються:
- slow queries та latency;
- блокування і кількість активних транзакцій;
- навантаження на БД;
- помилки застосунку (5xx) і час відповіді API;
- ключові бізнес-метрики (помилки оплати, конверсія).

Практично це реалізується через:
- метрики (Prometheus + Grafana);
- централізовані логи застосунку (ELK stack / Winston / NestJS Logger);
- error tracking (наприклад, Sentry).

---

### Етап 1. Expand (підготовка схеми)

На цьому етапі додаються всі зміни, потрібні новій архітектурі, **без поломки** старої версії застосунку:

- нові таблиці/колонки додаються **паралельно** до існуючих; старі не видаляються і не перейменовуються;
- зміни робляться **backward-compatible**, щоб стара та нова версії застосунку могли працювати одночасно під час переходу;
- у production уникаються blocking-операції та “важкі” `ALTER TABLE` (наприклад, `NOT NULL` без підготовки даних, зміна типів, `DROP` колонок);
- індекси додаються з мінімальними блокуваннями (для активних таблиць у production — `CREATE INDEX CONCURRENTLY`, де доречно);
- створення або зміна `FOREIGN KEY` виконується обережно, оскільки може блокувати не лише нову таблицю, а й таблицю, на яку вона посилається;
- constraints (`NOT NULL`, `UNIQUE`, `FOREIGN KEY`) на нових структурах вмикаються **поступово після backfill**, щоб уникати довгих блокувань і падінь через невалідні історичні дані.

---

### Етап 2. Dual-write та backfill

На перехідному етапі застосовується **dual-write**, щоб забезпечити синхронність між старою та новою схемами даних:

- нові записи одночасно зберігаються у стару та нову схеми на рівні application layer;
- використання тригерів у БД можливе як тимчасове рішення, але перевага надається dual-write в коді через прозорість логіки та простіший контроль;
- dual-write дозволяє безпечно підтримувати обидві схеми до моменту повного переходу.

Усі операції dual-write мають бути **ідемпотентними**, зокрема через:
- використання стабільних business keys або `legacy_id`, зафіксованих у БД унікальними обмеженнями (`UNIQUE`);
- застосування idempotency keys для критичних операцій;
- використання `UPSERT`-операцій (`ON CONFLICT DO NOTHING / UPDATE`);
- контроль повторних записів на рівні застосунку.

Для перенесення історичних даних використовується **backfill**.  
Backfill зазвичай реалізується на рівні застосунку з використанням механізмів БД
(транзакції, `UNIQUE`, `UPSERT`) для забезпечення консистентності.

- backfill виконується **батчами** з контрольованою швидкістю, щоб не перевантажувати БД;
- процес є ідемпотентним та може безпечно перезапускатись;
- прогрес backfill контролюється (cursor, timestamp, offset або службове поле статусу);
- під час backfill підтримується консистентність між старою та новою схемами.

---

### Етап 3. Read switch (перемикання читання)

Після стабілізації dual-write та виконання основного backfill
виконується **поступове перемикання читання** зі старої схеми на нову:

- читання перемикається поетапно через **feature flags** або конфігурацію;
- спочатку переводяться **low-risk** частини системи або обмежена частка трафіку
  (наприклад, 5–10% користувачів), далі — критичні user flows та повний трафік;
- на перехідному етапі можливі **shadow reads** для виявлення та усунення розбіжностей
  між старою та новою схемами без впливу на користувача;
- стабільність контролюється через моніторинг помилок, latency та бізнес-метрик.

Read switch забезпечує **швидкий rollback**:
- у разі проблем читання миттєво повертається на стару схему без втрати даних;
- dual-write зберігає актуальність обох схем до повної стабілізації.

---

### Етап 4. Contract (завершення міграції)

Після стабільної роботи системи на новій схемі виконується **contract-етап**, який завершує міграцію:

- dual-write вимикається лише після того, як read switch повністю завершено та підтверджена стабільність;
- застарілий код, який працював зі старою схемою, видаляється або вимикається;
- старі таблиці/колонки переводяться у режим “deprecated” і видаляються **поступово**
  (після узгодженого періоду стабілізації);
- фінально вмикаються або посилюються constraints та індекси на новій схемі
  (якщо частина з них була відкладена до завершення backfill);
- після завершення — додаткова валідація (контрольні перевірки та моніторинг)
  і тільки тоді прибирання legacy-структур.

---
## 2. Конкурентна покупка останнього товару на складі

### Які проблеми можуть виникнути

- **Overselling:** обидва користувачі успішно оформлюють замовлення, хоча товар лише один.
- **Race conditions:** перевірка наявності та списання виконуються неатомарно.
- **Подвійні або завислі платежі:** обидва користувачі можуть оплатити, після чого одному необхідно виконувати refund.
- **Неконсистентний UI:** через кеш, репліки або затримки оновлення користувачі бачать застарілий залишок.
- **Lock contention / deadlocks:** некоректна стратегія блокувань призводить до деградації продуктивності.
- **Повторні запити:** повторні кліки або retries без ідемпотентності створюють дублікати замовлень або резервів.

---

### Архітектурні підходи до вирішення

#### Підхід 1. Песимістичне блокування в БД

**Ідея:** перевірка наявності та списання товару виконуються в межах однієї транзакції з блокуванням рядка.

- використовується `SELECT ... FOR UPDATE` для рядка товару або складу;
- перевіряється, що `stock > 0`;
- виконується списання `stock = stock - 1`;
- транзакція фіксується та створюється замовлення.

**Переваги:**
- проста реалізація;
- сильна консистентність (ACID).

**Недоліки:**
- погано масштабується для “гарячих” товарів;
- можливе зростання latency через черги на блокування.

---

#### Підхід 2. Оптимістична конкуренція (CAS / conditional update)

**Ідея:** списання виконується атомарною операцією без попереднього блокування.

- `UPDATE products SET stock = stock - 1 WHERE id = :id AND stock > 0`;
- якщо `rows_affected = 1` — товар успішно зарезервований або списаний;
- якщо `0` — товар уже недоступний.

**Переваги:**
- мінімальні блокування;
- добре працює при високій конкуренції.

**Недоліки:**
- складніше обробляти edge cases;
- потребує чіткої ідемпотентності та компенсацій.

---

#### Підхід 3. Резервації з TTL + асинхронна обробка

**Ідея:** відокремити резервування товару від процесу оплати.

- при натисканні “Оплатити” створюється **reservation** з TTL (наприклад, 10 хв);
- товар переводиться з `available` у `reserved`;
- після успішної оплати reservation підтверджується;
- якщо оплата не завершена до завершення TTL — reservation автоматично скасовується;
- для високого навантаження операції можуть оброблятись через чергу.

Для обробки високої конкуренції по одному товару може використовуватись черга
з гарантією порядку обробки (**FIFO**):

- події резервування для одного товару обробляються послідовно в порядку надходження;
- це усуває race conditions між паралельними запитами;
- перший запит у черзі отримує резерв, наступні — коректну відмову або очікування.

**Переваги:**
- відсутність overselling;
- кращий UX і менше refund-сценаріїв;
- добра масштабованість.

**Недоліки:**
- складніша архітектура;
- eventual consistency між компонентами.

---

#### Saga та компенсуючі дії

Для multi-step процесів (reserve → pay → confirm) доцільно застосовувати **Saga pattern**:

- кожен крок має компенсуючу дію;
- у разі помилки або таймауту виконується компенсація (наприклад, `releaseReservation`);
- консистентність досягається без використання distributed transactions.

---

### Додаткові зауваження

- усі операції створення замовлень, резервів та обробки платежів мають бути **ідемпотентними**;
- UI має відображати не фізичний залишок, а фактичну доступність товару для замовлення з урахуванням активних резервів, щоб уникнути overselling і помилкових оплат.
---
## 3. Баг у калькуляторі знижок і перерахунок замовлень

### Технічний підхід до виявлення affected замовлень

1. Визначається точний період дії бага та версія логіки калькулятора.
2. Для всіх замовлень у цьому часовому вікні виконується **повторний розрахунок** суми з використанням виправленої логіки.
3. Результати перерахунку зберігаються в окремій технічній таблиці (наприклад, `order_adjustments`) з полями:
   - `order_id`, `customer_id`, `charged_amount`, `expected_amount`, `delta`, `status`.
4. Замовлення класифікуються:
   - `delta < 0` — клієнт **переплатив**;
   - `delta > 0` — клієнт **недоплатив**.
5. Виконуються агрегатні перевірки (кількість замовлень, сумарний delta) та вибіркова валідація edge cases.

Усі операції перерахунку є **ідемпотентними** та можуть безпечно повторюватись.

Для автоматизації подальших дій у таблиці `order_adjustments`
зберігаються також технічні та контактні дані, необхідні для процесингу:

- `customer_email` — для комунікації з клієнтом;
- `payment_provider` і `payment_reference_id` (payment intent / charge id) —
  для виконання refund або повторного списання через платіжного провайдера;
- `payment_method_status` — для визначення можливості автоматичного чарджу.

Повторне списання коштів виконується **не напряму по клієнту**, а через платіжного
провайдера з використанням збережених reference-id та токенізованих платіжних методів
(за наявності відповідного мандату).

---

### Автоматизація refunds / charges з урахуванням expired карток

Процес обробки будується з урахуванням бізнес-пріоритетів та мінімізації негативного
впливу на клієнтів.

#### Замовлення з недоплатою (~4 000)

- **Якщо платіжний метод валідний**:
  - виконується автоматичний дозбір різниці (off-session charge, якщо дозволяє провайдер);
  - клієнту надсилається повідомлення з поясненням ситуації та вибаченням;
  - як компенсація пропонується бонус (наприклад, промокод на 5% для майбутніх покупок від певної суми).
- **Якщо картка expired або автоматичний чардж неможливий**:
  - надсилається email із поясненням та запитом оновити платіжні дані;
  - виконується кілька follow-up повідомлень;
  - за необхідності кейс передається у customer support для телефонного контакту;
  - після обмеженої кількості спроб процес припиняється.

#### Замовлення з переплатою (~8 000)

- Refund **не виконується автоматично**.
- Клієнту надсилається повідомлення з можливістю вибору:
  - отримати refund;
  - отримати store credit (wallet balance) для майбутніх покупок;
  - не виконувати жодних дій.
- Якщо клієнт не відповів — додаткових дій не виконується.
- Обраний клієнтом варіант обробляється автоматизовано та ідемпотентно.

---

### Комунікація з клієнтами

- Прозора та проактивна комунікація:
  - пояснення суті технічної помилки;
  - чітке формулювання впливу на конкретне замовлення;
  - вибачення за незручності.
- Повідомлення персоналізуються залежно від сценарію (переплата / недоплата).
- Тон комунікації — customer-centric, без перекладання відповідальності.
- Для складних або спірних кейсів залучається служба підтримки.

---

### Запобігання подібним інцидентам у майбутньому

- Версіонування та ізоляція бізнес-логіки калькулятора знижок.
- Unit та integration тести для ключових сценаріїв (промокоди, річні плани, комбінації знижок).
- Періодичний shadow recalculation у production з порівнянням результатів.
- Алерти на аномальні відхилення в середньому чеку та сумі знижок.
- Audit-лог змін у правилах ціноутворення.
- Використання feature flags для безпечного rollout змін:
  нові правила ціноутворення вмикаються поступово (наприклад, для частини замовлень або користувачів),
  з можливістю миттєвого вимкнення у разі виявлення аномалій,
  без повторного деплою та з мінімальним впливом на клієнтів.
---
## 4. Архітектура multi-tenant SaaS e-commerce платформи

### Одна БД чи database-per-tenant

**Базовий підхід: одна спільна PostgreSQL БД (shared) + `merchant_id`**
- Усі таблиці містять `merchant_id` (tenant id).
- Простота експлуатації: міграції, аналітика, бекопи, моніторинг.
- Масштабування через індекси, партиціювання, read replicas, кеш.

**Hybrid модель для великих merchants**
- За замовчуванням — shared DB.
- Для великих або enterprise merchants — **database-per-tenant** або окремий кластер.
- Дозволяє ізолювати навантаження та масштабувати окремого клієнта без впливу на інших.

---

### Ізоляція даних між merchants

**Рівень БД**
- Усі записи містять `merchant_id`.
- Композитні індекси (наприклад, `(merchant_id, created_at)`, `(merchant_id, sku)`).
- Tenant-aware унікальність (`UNIQUE(merchant_id, external_id)`).

**Row-Level Security (RLS) як додатковий захист**
- Політики PostgreSQL RLS обмежують доступ до рядків за `merchant_id`.
- Tenant context встановлюється на рівні конекшена (`SET app.merchant_id = ...`).
- Навіть у разі помилки в коді “чужі” дані не можуть бути прочитані.

**Рівень застосунку**
- Tenant resolution через subdomain / headers / JWT claims.
- Tenant-aware репозиторії та ORM-scopes.
- Логи та audit-записи завжди містять `merchant_id`.

---

### Кастомізація без форків коду

**1) Конфігураційна кастомізація (основний сценарій)**
- Правила знижок, податків, доставки — як дані (таблиці / конфіги).
- Калькулятори працюють через інтерфейси, реалізація вибирається за `merchant_id`.

**2) Rules engine / DSL**
- Знижки описуються правилами (JSON / DSL), а не кодом.
- Дозволяє змінювати формули без деплою та без форків.

**3) Інтеграції через події**
- Подієва модель (OrderCreated, PaymentSucceeded, RefundIssued).
- Webhooks або адаптери для кожного merchant.
- Складні інтеграції — окремі integration apps.

**4) Плагінні інтерфейси для enterprise**
- Чіткі extension points (`DiscountProvider`, `TaxProvider`, `FulfillmentProvider`).
- Плагіни вибираються через конфігурацію, а не через гілки коду.
- Версіонування та контракти замість форків.

---

### Межа між shared і isolated компонентами

**Shared**
- Core домени: каталог, замовлення, платежі, користувачі, базовий pricing.
- Auth, API gateway, rate limiting.
- Загальна інфраструктура: кеш, черги, observability.

**Isolated (за потреби)**
- Окремі БД або схеми для великих merchants.
- Виділені воркери та черги.
- Окремі квоти та ліміти.
- Ізольовані інтеграції, якщо вони створюють значне навантаження.

---

### Масштабування, якщо один merchant виросте в 100x

**БД**
- Перехід merchant на database-per-tenant або окремий кластер.
- Партиціювання orders (за `merchant_id` або часом).
- Read replicas, окремі connection pools.
- Кешування “гарячих” читань, CDN для медіа.

**Застосунок**
- Tenant-based rate limits та квоти.
- Виділені черги та воркери.
- Backpressure, retry-політики, circuit breakers для інтеграцій.

**Архітектура**
- Модульний моноліт → виділення гарячих доменів (Orders/Payments) за потреби.
- Без передчасної мікросервісизації.
- Для enterprise — можливість dedicated environment як комерційного tier.

---

### Аналітика та звітність (OLAP) окремо від OLTP

OLTP база даних **не використовується напряму для аналітики**, щоб уникнути
впливу важких запитів на production.

- Дані експортуються в аналітичний контур (Data Warehouse / columnar storage)
  через ETL/ELT або подієву модель.
- Аналітика будується поза core системою, без довгих транзакцій і блокувань.

Для швидкого запуску merchant-орієнтованої аналітики доцільний **підхід Kimball (bottom-up)**:
- аналітика організована у вигляді Data Marts (sales, revenue, refunds, conversion);
- кожен Data Mart оптимізований під конкретні бізнес-запити;
- підхід добре масштабується разом із ростом платформи.

Більш централізовані або складні моделі (Inmon / Data Vault) можуть бути
розглянуті пізніше, коли з’являється потреба в глибокій історичності
та складній міждоменній аналітиці.

---

### Підсумок

- Core система: **shared PostgreSQL + tenant_id** з можливістю hybrid-ізоляції.
- Ізоляція: поєднання application-level логіки та RLS.
- Кастомізація: конфігурації, rules engine, події, плагінні інтерфейси без форків.
- Масштабування: ізоляція важких merchants на рівні БД, воркерів та квот.
- Аналітика: окремий OLAP-контур з Kimball-підходом для швидких бізнес-звітів.
